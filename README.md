# Multimodal Visual Reasoning Dataset (MVR)

This dataset focuses on object detection and reasoning in complex environments. It includes an **Artificial Camouflage Dataset** (Visible/Infrared modalities) and a **Natural Biological Camouflage Dataset** (Image/Text modalities). It aims to advance research in cross-modal fusion, camouflaged object detection, and explainable reasoning. Future extensions will incorporate clue-chain-based deep reasoning tasks.

## 1. Visible-Infrared Artificial Camouflage Dataset (VIAC)

This dataset is constructed using customized metal models and camouflage materials. Artificial scenes were built, and synchronized aerial data was collected using DJI drones equipped with dual-mode visible and infrared cameras in complex outdoor environments. The visible images provide color-texture clues, while infrared images highlight thermal radiation differences, supporting camouflaged object detection and reasoning under challenging conditions.

### Dataset Overview

- **Image Pairs**: 1,500 spatially aligned visible-infrared image pairs.
- **Annotations**: Pixel-wise segmentation masks.
- **Camouflage Types**:  
  - *Plant Camouflage*: Vehicles hidden by natural vegetation  
  - *Camouflage Net*: Vehicles covered by camouflage nets  
  - *Camouflage Suit*: People wearing camouffage suit
- **Camouflage Challenges**: The dataset includes nine challenge factors, considering illumination, object class, size, count, and spatial complexity:
  - BCO: Big Camouflaged Object
  - SCO: Small Camouflaged Object
  - MCO: Multiple Camouflaged Objects
  - CB: Center Bias
  - OV: Out of View
  - OC: Occlusions
  - TC: Thermal Crossover
  - IC: Image Clutter
  - LI: Low Illumination

### Directory Structure

- Root directory contains:
  - `Visible/` – Visible images  
  - `Infrared/` – Infrared images  
  - `GT/` – Segmentation masks  

## 2. Natural Biological Camouflage Multimodal Dataset (NBCM)

Based on the existing COD10K dataset, this extension adds structured annotations that describe spatial relationships between camouflaged objects and background distractors, enhancing spatial reasoning. Each image is paired with a textual description to support image-text multimodal reasoning.

### Dataset Overview

- **Image-Text Pairs**: 5,066 natural camouflage images (plants/animals) with spatial relationship descriptions (e.g., *"The octopus is on the coral reef surface"*).
- **Annotations**:  
  - Structured spatial relationship tags  
  - Pixel-wise segmentation masks
- **Position Relationships**:
  - *Surround*: Camouflaged object is surrounded by background
  - *Surface*: Camouflaged object lies on the surface of background
  - *Beside*: Camouflaged object is adjacent to background
  - *Inside*: Camouflaged object is partially or fully embedded within background
  - *Cover*: Camouflaged object is occluded by background

### Directory Structure

- Root directory contains:
  - `Num/`
    - `JPEGImage/` – Original images  
    - `SegmentationClass/` – Segmentation masks  
    - `annotations.xml` – Structured relationship annotations  

## 3. Future Extensions

### Data Expansion

- Increase the scale of VIAC using generative data augmentation and additional real-world field collections.

### Reasoning Chain Annotations

- Add multi-step reasoning chains to each data pair, guiding visual localization through progressive clues from different modalities.
- Design a reasoning logic template that combines visible cues (color, texture) with infrared cues (thermal radiation anomalies) (such as "visible concealment → infrared saliency → target localization").

Example reasoning chain:
```json
{
  "image_id": "MVR_0001",
  "reasoning_chain": [
    "The infrared image shows thermal anomalies on vehicle metal parts (thermal clue).",
    "The corresponding region in the visible image has textures consistent with vegetation (visual camouflage).",
    "Conclusion: The vehicle is camouflaged under vegetation, but thermal signals from exposed metal parts are visible."
  ]
}
```

- LLM-assisted annotation: Chains are initially generated by GPT-4 and then manually verified before inclusion.

### Dynamic Environment Extension

- Introduce visible-infrared video pairs to capture motion trajectories and thermal variations over time. This supports temporal-spatial reasoning in multimodal settings.

---

## Access & License

To access the dataset and related resources, please visit: [GitHub or dataset hosting link here]

Our dataset is free for non-commercial usage. Please contact us if you want to use it for comercial usage.
